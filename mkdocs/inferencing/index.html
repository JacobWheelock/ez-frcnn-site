<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://ez-frcnn.github.io/inferencing/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>ez-frcnn.inferencing - EZ-FRCNN</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "ez-frcnn.inferencing";
        var mkdocs_page_input_path = "inferencing.md";
        var mkdocs_page_url = "/inferencing/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> EZ-FRCNN
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../annotation/">ez-frcnn.annotation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../characterize/">ez-frcnn.characterize</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../image_augs/">ez-frcnn.image_augs</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">ez-frcnn.inferencing</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.load_model">load_model</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.saveResultsToCSV">saveResultsToCSV</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.inference_video">inference_video</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.inference_images">inference_images</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.load_and_preprocess_image">load_and_preprocess_image</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.scale_boxes_to_original">scale_boxes_to_original</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.inference_images_fast">inference_images_fast</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#library.inferencing.inference_images_figs">inference_images_figs</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../plotting/">ez-frcnn.plotting</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../training/">ez-frcnn.training</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utils/">ez-frcnn.utils</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">EZ-FRCNN</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">ez-frcnn.inferencing</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="ez-frcnninferencing">ez-frcnn.inferencing</h1>
<hr />
<pre><code class="language-py">def inferencing.load_model(model_name, MODEL_DIR, NUM_CLASSES):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.load_model"></a>
    <div class="doc doc-contents first">

        <p>Loads a trained model from disk and prepares it for evaluation.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>model_name (str):  Filename of the saved model weights.
MODEL_DIR (str):   Directory path where the model files are stored.
NUM_CLASSES (int): Number of output classes for the model.</p>
</details>

<details class="output" open>
  <summary>Output</summary>
  <p>nn.Module: The loaded PyTorch model set to evaluation mode on the appropriate device.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">MODEL_DIR</span><span class="p">,</span> <span class="n">NUM_CLASSES</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads a trained model from disk and prepares it for evaluation.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        model_name (str):  Filename of the saved model weights.</span>
<span class="sd">        MODEL_DIR (str):   Directory path where the model files are stored.</span>
<span class="sd">        NUM_CLASSES (int): Number of output classes for the model.</span>

<span class="sd">    Output:</span>
<span class="sd">        nn.Module: The loaded PyTorch model set to evaluation mode on the appropriate device.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set the computation device</span>
    <span class="n">modelPath</span> <span class="o">=</span> <span class="s1">&#39;./models/&#39;</span> <span class="o">+</span> <span class="n">model_name</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="c1"># load the model and the trained weights</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">NUM_CLASSES</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">modelPath</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span>
    <span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.saveResultsToCSV(csvFileName, results, OUT_DIR):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.saveResultsToCSV"></a>
    <div class="doc doc-contents first">

        <p>Saves detection results to a CSV file with specified columns.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>csvFileName (str):      Name of the CSV file (without extension) to save results.
results (list of dict): List of detection result dictionaries containing keys
                        'image_name', 'boxes', 'classes', and 'scores'.
OUT_DIR (str):          Directory path where the CSV file will be saved.</p>
</details>

<details class="output" open>
  <summary>Output</summary>
  <p>None: Writes the results to a CSV file at the specified location.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">saveResultsToCSV</span><span class="p">(</span><span class="n">csvFileName</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves detection results to a CSV file with specified columns.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        csvFileName (str):      Name of the CSV file (without extension) to save results.</span>
<span class="sd">        results (list of dict): List of detection result dictionaries containing keys</span>
<span class="sd">                                &#39;image_name&#39;, &#39;boxes&#39;, &#39;classes&#39;, and &#39;scores&#39;.</span>
<span class="sd">        OUT_DIR (str):          Directory path where the CSV file will be saved.</span>

<span class="sd">    Output:</span>
<span class="sd">        None: Writes the results to a CSV file at the specified location.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">csv_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">csvFileName</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">)</span>

    <span class="c1"># Open CSV file and write the data</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">csv_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">quoting</span><span class="o">=</span><span class="n">csv</span><span class="o">.</span><span class="n">QUOTE_ALL</span><span class="p">)</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="s1">&#39;Image Name&#39;</span><span class="p">,</span> <span class="s1">&#39;Bounding Boxes&#39;</span><span class="p">,</span> <span class="s1">&#39;Classes&#39;</span><span class="p">,</span> <span class="s1">&#39;Scores&#39;</span><span class="p">])</span>  <span class="c1"># CSV Header</span>

        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;image_name&#39;</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;boxes&#39;</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;classes&#39;</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;scores&#39;</span><span class="p">]])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.inference_video(DIR_TEST, OUT_DIR, vidName, model, detection_threshold, CLASSES, save_detections=False):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.inference_video"></a>
    <div class="doc doc-contents first">

        <p>Runs object detection on a video, annotates detected objects frame-by-frame, 
optionally saves detected regions, and writes the annotated video to disk.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>DIR_TEST (str):                   Path to the input video file for inference.
OUT_DIR (str):                    Directory where output video and detected regions (optional) will be saved.
vidName (str):                    Filename for the output annotated video.
model (torch.nn.Module):          Trained object detection model.
detection_threshold (float):      Confidence threshold for filtering detections.
CLASSES (list):                   List of class names corresponding to model outputs.
save_detections (bool, optional): If True, saves detected bounding box regions as separate images. Default is False.</p>
</details>

<details class="outputs" open>
  <summary>Outputs</summary>
  <p>list: A list containing three elements for all frames:
    - bboxes (list): Detected bounding boxes per frame.
    - classes (list): Detected class labels per frame.
    - sscores (list): Detection scores per frame.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">inference_video</span><span class="p">(</span><span class="n">DIR_TEST</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">,</span> <span class="n">vidName</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">detection_threshold</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">,</span> <span class="n">save_detections</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Runs object detection on a video, annotates detected objects frame-by-frame, </span>
<span class="sd">    optionally saves detected regions, and writes the annotated video to disk.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        DIR_TEST (str):                   Path to the input video file for inference.</span>
<span class="sd">        OUT_DIR (str):                    Directory where output video and detected regions (optional) will be saved.</span>
<span class="sd">        vidName (str):                    Filename for the output annotated video.</span>
<span class="sd">        model (torch.nn.Module):          Trained object detection model.</span>
<span class="sd">        detection_threshold (float):      Confidence threshold for filtering detections.</span>
<span class="sd">        CLASSES (list):                   List of class names corresponding to model outputs.</span>
<span class="sd">        save_detections (bool, optional): If True, saves detected bounding box regions as separate images. Default is False.</span>

<span class="sd">    Outputs:</span>
<span class="sd">        list: A list containing three elements for all frames:</span>
<span class="sd">            - bboxes (list): Detected bounding boxes per frame.</span>
<span class="sd">            - classes (list): Detected class labels per frame.</span>
<span class="sd">            - sscores (list): Detection scores per frame.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">vid</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">DIR_TEST</span><span class="p">)</span>
    <span class="n">property_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_COUNT</span><span class="p">)</span> 
    <span class="n">NUM_FRAMES</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">vid</span><span class="p">,</span> <span class="n">property_id</span><span class="p">))</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">frame_width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">frame_height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
    <span class="c1"># Define the codec and create VideoWriter object.The output is stored in &#39;outpy.avi&#39; file.</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">((</span><span class="n">OUT_DIR</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">vidName</span><span class="p">),</span><span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="s1">&#39;M&#39;</span><span class="p">,</span><span class="s1">&#39;J&#39;</span><span class="p">,</span><span class="s1">&#39;P&#39;</span><span class="p">,</span><span class="s1">&#39;G&#39;</span><span class="p">),</span> <span class="mi">30</span><span class="p">,</span> <span class="p">(</span><span class="n">frame_width</span><span class="p">,</span><span class="n">frame_height</span><span class="p">))</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">NUM_FRAMES</span>
    <span class="n">bboxes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">NUM_FRAMES</span>
    <span class="n">sscores</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">NUM_FRAMES</span>

    <span class="k">while</span> <span class="n">vid</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
        <span class="n">ret</span><span class="p">,</span> <span class="n">image</span> <span class="o">=</span> <span class="n">vid</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

        <span class="n">orig_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># BGR to RGB</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="c1"># make the pixel range between 0 and 1</span>
        <span class="n">image</span> <span class="o">/=</span> <span class="mf">255.0</span>
        <span class="c1"># bring color channels to front</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># convert to tensor</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># add batch dimension</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># load all detection to CPU for further operations</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
        <span class="c1"># carry further only if there are detected boxes</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;boxes&#39;</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;boxes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;scores&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">sscores</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span>

            <span class="c1"># filter out boxes according to `detection_threshold`</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">bboxes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">boxes</span>
            <span class="n">draw_boxes</span> <span class="o">=</span> <span class="n">bboxes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 

            <span class="c1"># get all the predicited class names</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">CLASSES</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred_classes</span><span class="p">)</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">pred_classes</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span>
            <span class="n">classes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_classes</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">save_detections</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">box</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">draw_boxes</span><span class="p">):</span>
                    <span class="c1"># Extract and save each detected region</span>
                    <span class="n">detected_region</span> <span class="o">=</span> <span class="n">orig_image</span><span class="p">[</span><span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">box</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">box</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
                    <span class="n">region_save_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">OUT_DIR</span><span class="si">}</span><span class="s2">/frame_</span><span class="si">{</span><span class="n">idx</span><span class="si">:</span><span class="s2">04d</span><span class="si">}</span><span class="s2">_box_</span><span class="si">{</span><span class="n">j</span><span class="si">:</span><span class="s2">02d</span><span class="si">}</span><span class="s2">.png&quot;</span>
                    <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">region_save_path</span><span class="p">,</span> <span class="n">detected_region</span><span class="p">)</span>
            <span class="c1"># draw the bounding boxes and write the class name on top of it</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">box</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">draw_boxes</span><span class="p">):</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span>
                            <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
                            <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">3</span><span class="p">])),</span>
                            <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">pred_classes</span><span class="p">[</span><span class="n">j</span><span class="p">]),</span> 
                            <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">5</span><span class="p">)),</span>
                            <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> 
                            <span class="mi">2</span><span class="p">,</span> <span class="n">lineType</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>
            <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">orig_image</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> done...&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="n">NUM_FRAMES</span><span class="p">:</span>
            <span class="n">vid</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TEST PREDICTIONS COMPLETE&#39;</span><span class="p">)</span> 
    <span class="k">return</span> <span class="p">[</span><span class="n">bboxes</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">sscores</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.inference_images(DIR_TEST, model, OUT_DIR, detection_threshold, CLASSES, tqdmBar, inf_fig):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.inference_images"></a>
    <div class="doc doc-contents first">

        <p>Performs object detection on all images in a specified directory, annotates and saves the results, 
and records detection details for further analysis.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>DIR_TEST (str):              Path to the directory containing input images.
model (torch.nn.Module):     Trained object detection model.
OUT_DIR (str):               Directory where annotated images and results CSV will be saved.
detection_threshold (float): Confidence threshold for filtering detections.
CLASSES (list):              List of class names corresponding to model output labels.
tqdmBar (callable):          Progress bar function for iterating over images.
inf_fig (object):            Visualization object used to display annotated images.</p>
</details>

<details class="outputs" open>
  <summary>Outputs</summary>
  <p>list: A list of dictionaries, each containing:
    - 'image_name' (str): Filename of the image.
    - 'boxes' (list):     Detected bounding boxes as lists of coordinates.
    - 'classes' (list):   Predicted class labels.
    - 'scores' (list):    Confidence scores for detections.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">inference_images</span><span class="p">(</span><span class="n">DIR_TEST</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">,</span> <span class="n">detection_threshold</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">,</span> <span class="n">tqdmBar</span><span class="p">,</span> <span class="n">inf_fig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs object detection on all images in a specified directory, annotates and saves the results, </span>
<span class="sd">    and records detection details for further analysis.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        DIR_TEST (str):              Path to the directory containing input images.</span>
<span class="sd">        model (torch.nn.Module):     Trained object detection model.</span>
<span class="sd">        OUT_DIR (str):               Directory where annotated images and results CSV will be saved.</span>
<span class="sd">        detection_threshold (float): Confidence threshold for filtering detections.</span>
<span class="sd">        CLASSES (list):              List of class names corresponding to model output labels.</span>
<span class="sd">        tqdmBar (callable):          Progress bar function for iterating over images.</span>
<span class="sd">        inf_fig (object):            Visualization object used to display annotated images.</span>

<span class="sd">    Outputs:</span>
<span class="sd">        list: A list of dictionaries, each containing:</span>
<span class="sd">            - &#39;image_name&#39; (str): Filename of the image.</span>
<span class="sd">            - &#39;boxes&#39; (list):     Detected bounding boxes as lists of coordinates.</span>
<span class="sd">            - &#39;classes&#39; (list):   Predicted class labels.</span>
<span class="sd">            - &#39;scores&#39; (list):    Confidence scores for detections.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">imagePath</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DIR_TEST</span><span class="si">}</span><span class="s2">/*.png&quot;</span><span class="p">)</span>
    <span class="n">image_extensions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;gif&#39;</span><span class="p">,</span> <span class="s1">&#39;bmp&#39;</span><span class="p">,</span> <span class="s1">&#39;tiff&#39;</span><span class="p">,</span> <span class="s1">&#39;webp&#39;</span><span class="p">,</span> <span class="s1">&#39;tif&#39;</span><span class="p">]</span>
    <span class="n">all_extensions</span> <span class="o">=</span> <span class="n">image_extensions</span> <span class="o">+</span> <span class="p">[</span><span class="n">ext</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">image_extensions</span><span class="p">]</span>  <span class="c1"># Add uppercase versions</span>
    <span class="k">for</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">all_extensions</span><span class="p">:</span>
            <span class="n">imagePath</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DIR_TEST</span><span class="si">}</span><span class="s2">/*.</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
    <span class="n">all_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">image_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">imagePath</span><span class="p">]</span>
    <span class="n">all_images</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>
    <span class="n">bboxes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>
    <span class="n">sscores</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>
    <span class="c1"># List to store results for CSV</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">tqdmBar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_images</span><span class="p">)):</span>
        <span class="n">el</span> <span class="o">=</span> <span class="n">all_images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">orig_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">DIR_TEST</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">el</span><span class="p">)</span>
        <span class="c1"># BGR to RGB</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="c1"># make the pixel range between 0 and 1</span>
        <span class="n">image</span> <span class="o">/=</span> <span class="mf">255.0</span>
        <span class="c1"># bring color channels to front</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># convert to tensor</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="c1"># add batch dimension</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># load all detection to CPU for further operations</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
        <span class="c1"># carry further only if there are detected boxes</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;boxes&#39;</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;boxes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;scores&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">sscores</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span>

            <span class="c1"># filter out boxes according to `detection_threshold`</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">bboxes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">boxes</span>
            <span class="n">draw_boxes</span> <span class="o">=</span> <span class="n">bboxes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 

            <span class="c1"># get all the predicited class names</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">CLASSES</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred_classes</span><span class="p">)</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">pred_classes</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span>
            <span class="n">classes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_classes</span>
            <span class="c1"># Store results for this image in the list</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;image_name&#39;</span><span class="p">:</span> <span class="n">el</span><span class="p">,</span>
                <span class="s1">&#39;boxes&#39;</span><span class="p">:</span> <span class="n">boxes</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                <span class="s1">&#39;classes&#39;</span><span class="p">:</span> <span class="n">pred_classes</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                <span class="s1">&#39;scores&#39;</span><span class="p">:</span> <span class="n">sscores</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="p">})</span>
            <span class="c1"># draw the bounding boxes and write the class name on top of it</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
            <span class="n">orig_image_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">orig_image_rgb</span><span class="p">)</span>

            <span class="n">inf_fig</span><span class="o">.</span><span class="n">object</span> <span class="o">=</span> <span class="n">fig</span>
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">box</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">draw_boxes</span><span class="p">):</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">orig_image_rgb</span><span class="p">,</span>
                            <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
                            <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">3</span><span class="p">])),</span>
                            <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">orig_image_rgb</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">pred_classes</span><span class="p">[</span><span class="n">j</span><span class="p">]),</span> 
                            <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">int</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">5</span><span class="p">)),</span>
                            <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> 
                            <span class="mi">2</span><span class="p">,</span> <span class="n">lineType</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>
            <span class="n">writeOut</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">orig_image_rgb</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">OUT_DIR</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">el</span><span class="p">,</span> <span class="n">writeOut</span><span class="p">)</span> <span class="c1">#The &#39;el&#39; filepath is broken right now (TODO: FIX) </span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  <span class="c1"># Remove the axis for cleaner visualization</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">orig_image_rgb</span><span class="p">)</span>
            <span class="c1"># Update the inf_fig pane with the new figure</span>
            <span class="n">inf_fig</span><span class="o">.</span><span class="n">object</span> <span class="o">=</span> <span class="n">fig</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="c1">#print(f&quot;Image {idx+1} done...&quot;)</span>
        <span class="c1">#print(&#39;-&#39;*50)</span>

    <span class="n">saveResultsToCSV</span><span class="p">(</span><span class="s1">&#39;inference_results&#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TEST PREDICTIONS COMPLETE&#39;</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.load_and_preprocess_image(file_path, target_size=(800, 800)):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.load_and_preprocess_image"></a>
    <div class="doc doc-contents first">

        <p>Loads an image from disk, resizes it to a target size, converts it to RGB, normalizes pixel values,
and transforms it into a PyTorch tensor suitable for model input.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>file_path (str):     Path to the input image file.
target_size (tuple): Desired output image size as (width, height). Default is (800, 800).</p>
</details>

<details class="outputs" open>
  <summary>Outputs</summary>
  <p>tuple: A tuple containing:
    - image_tensor (torch.Tensor): Preprocessed image tensor of shape (3, target_height, target_width).
    - filename (str):              The basename of the input image file.
    - original_size (tuple):       Original image dimensions as (width, height).</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_and_preprocess_image</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">800</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads an image from disk, resizes it to a target size, converts it to RGB, normalizes pixel values,</span>
<span class="sd">    and transforms it into a PyTorch tensor suitable for model input.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        file_path (str):     Path to the input image file.</span>
<span class="sd">        target_size (tuple): Desired output image size as (width, height). Default is (800, 800).</span>

<span class="sd">    Outputs:</span>
<span class="sd">        tuple: A tuple containing:</span>
<span class="sd">            - image_tensor (torch.Tensor): Preprocessed image tensor of shape (3, target_height, target_width).</span>
<span class="sd">            - filename (str):              The basename of the input image file.</span>
<span class="sd">            - original_size (tuple):       Original image dimensions as (width, height).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">orig_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="n">orig_height</span><span class="p">,</span> <span class="n">orig_width</span> <span class="o">=</span> <span class="n">orig_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">resized_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">target_size</span><span class="p">)</span>  <span class="c1"># Resize to fixed size</span>
    <span class="n">image_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">resized_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">image_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image_rgb</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image_tensor</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">file_path</span><span class="p">),</span> <span class="p">(</span><span class="n">orig_width</span><span class="p">,</span> <span class="n">orig_height</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.scale_boxes_to_original(boxes, original_size, resized_size=(800, 800)):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.scale_boxes_to_original"></a>
    <div class="doc doc-contents first">

        <p>Scales bounding box coordinates from a resized image back to the original image dimensions.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>boxes (array-like):    Array of bounding boxes with coordinates [x_min, y_min, x_max, y_max] 
                       relative to the resized image.
original_size (tuple): Original image size as (width, height).
resized_size (tuple):  Resized image size as (width, height). Default is (800, 800).</p>
</details>

<details class="outputs" open>
  <summary>Outputs</summary>
  <p>numpy.ndarray: Array of bounding boxes scaled to the original image size.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">scale_boxes_to_original</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">original_size</span><span class="p">,</span> <span class="n">resized_size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">800</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Scales bounding box coordinates from a resized image back to the original image dimensions.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        boxes (array-like):    Array of bounding boxes with coordinates [x_min, y_min, x_max, y_max] </span>
<span class="sd">                               relative to the resized image.</span>
<span class="sd">        original_size (tuple): Original image size as (width, height).</span>
<span class="sd">        resized_size (tuple):  Resized image size as (width, height). Default is (800, 800).</span>

<span class="sd">    Outputs:</span>
<span class="sd">        numpy.ndarray: Array of bounding boxes scaled to the original image size.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">orig_width</span><span class="p">,</span> <span class="n">orig_height</span> <span class="o">=</span> <span class="n">original_size</span>
    <span class="n">resized_width</span><span class="p">,</span> <span class="n">resized_height</span> <span class="o">=</span> <span class="n">resized_size</span>
    <span class="n">x_scale</span> <span class="o">=</span> <span class="n">orig_width</span> <span class="o">/</span> <span class="n">resized_width</span>
    <span class="n">y_scale</span> <span class="o">=</span> <span class="n">orig_height</span> <span class="o">/</span> <span class="n">resized_height</span>
    <span class="n">scaled_boxes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">box</span> <span class="ow">in</span> <span class="n">boxes</span><span class="p">:</span>
        <span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">box</span>
        <span class="n">scaled_boxes</span><span class="o">.</span><span class="n">append</span><span class="p">([</span>
            <span class="n">x_min</span> <span class="o">*</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_min</span> <span class="o">*</span> <span class="n">y_scale</span><span class="p">,</span>
            <span class="n">x_max</span> <span class="o">*</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">*</span> <span class="n">y_scale</span>
        <span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaled_boxes</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.inference_images_fast(DIR_TEST, model, OUT_DIR, detection_threshold, CLASSES, tqdmBar, batch_size=4):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.inference_images_fast"></a>
    <div class="doc doc-contents first">

        <p>Performs batch inference on images in a directory using the provided model, with optional GPU acceleration.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>DIR_TEST (str):              Directory path containing images for inference.
model (torch.nn.Module):     Trained object detection model.
OUT_DIR (str):               Directory path to save inference results.
detection_threshold (float): Minimum confidence score to consider a detection valid.
CLASSES (list):              List of class names corresponding to model labels.
tqdmBar (iterable):          Progress bar iterator for displaying progress.
batch_size (int, optional):  Number of images to process per batch. Default is 4.</p>
</details>

<details class="outputs" open>
  <summary>Outputs</summary>
  <p>list of dict: Each dict contains image filename, bounding boxes (scaled to original image size), 
              predicted classes, and detection scores for that image.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">inference_images_fast</span><span class="p">(</span><span class="n">DIR_TEST</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">,</span> <span class="n">detection_threshold</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">,</span> <span class="n">tqdmBar</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs batch inference on images in a directory using the provided model, with optional GPU acceleration.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        DIR_TEST (str):              Directory path containing images for inference.</span>
<span class="sd">        model (torch.nn.Module):     Trained object detection model.</span>
<span class="sd">        OUT_DIR (str):               Directory path to save inference results.</span>
<span class="sd">        detection_threshold (float): Minimum confidence score to consider a detection valid.</span>
<span class="sd">        CLASSES (list):              List of class names corresponding to model labels.</span>
<span class="sd">        tqdmBar (iterable):          Progress bar iterator for displaying progress.</span>
<span class="sd">        batch_size (int, optional):  Number of images to process per batch. Default is 4.</span>

<span class="sd">    Outputs:</span>
<span class="sd">        list of dict: Each dict contains image filename, bounding boxes (scaled to original image size), </span>
<span class="sd">                      predicted classes, and detection scores for that image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Collect all image paths</span>
    <span class="n">image_extensions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;gif&#39;</span><span class="p">,</span> <span class="s1">&#39;bmp&#39;</span><span class="p">,</span> <span class="s1">&#39;tiff&#39;</span><span class="p">,</span> <span class="s1">&#39;webp&#39;</span><span class="p">]</span>
    <span class="n">all_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">image_extensions</span> <span class="o">+</span> <span class="p">[</span><span class="n">ext</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">image_extensions</span><span class="p">]:</span>
        <span class="n">all_image_paths</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DIR_TEST</span><span class="si">}</span><span class="s2">/*.</span><span class="si">{</span><span class="n">ext</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
    <span class="n">all_image_paths</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_image_paths</span><span class="p">)</span>

    <span class="c1"># Prepare results list for annotations</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Device setup</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># Process images in batches</span>
    <span class="k">with</span> <span class="n">ThreadPoolExecutor</span><span class="p">()</span> <span class="k">as</span> <span class="n">executor</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">start_idx</span> <span class="ow">in</span> <span class="n">tqdmBar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_image_paths</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Inference Progress&quot;</span><span class="p">):</span>
            <span class="c1"># Load images in parallel</span>
            <span class="n">batch_paths</span> <span class="o">=</span> <span class="n">all_image_paths</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">batch_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">executor</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">load_and_preprocess_image</span><span class="p">,</span> <span class="n">batch_paths</span><span class="p">))</span>

            <span class="c1"># Separate image tensors and filenames</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">filenames</span><span class="p">,</span> <span class="n">original_sizes</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch_data</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Run inference</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>

            <span class="c1"># Process each image output</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
                <span class="n">scores</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;scores&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">boxes</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;boxes&#39;</span><span class="p">][</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">][</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

                <span class="c1"># Scale boxes back to original image size</span>
                <span class="n">orig_size</span> <span class="o">=</span> <span class="n">original_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">scaled_boxes</span> <span class="o">=</span> <span class="n">scale_boxes_to_original</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">orig_size</span><span class="p">)</span>

                <span class="c1"># Store annotation results</span>
                <span class="n">pred_classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">CLASSES</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
                <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;image_name&#39;</span><span class="p">:</span> <span class="n">filenames</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="s1">&#39;boxes&#39;</span><span class="p">:</span> <span class="n">scaled_boxes</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                    <span class="s1">&#39;classes&#39;</span><span class="p">:</span> <span class="n">pred_classes</span><span class="p">,</span>
                    <span class="s1">&#39;scores&#39;</span><span class="p">:</span> <span class="n">scores</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="p">}</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="c1"># Save results to JSON or CSV</span>
    <span class="n">saveResultsToCSV</span><span class="p">(</span><span class="s1">&#39;inference_results&#39;</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TEST PREDICTIONS COMPLETE&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><hr />
<pre><code class="language-py">def inferencing.inference_images_figs(DIR_TEST, model, OUT_DIR, detection_threshold, CLASSES):
</code></pre>


<div class="doc doc-object doc-function">



<a id="library.inferencing.inference_images_figs"></a>
    <div class="doc doc-contents first">

        <p>Performs inference on images in a directory using the given model, annotates detected objects with bounding boxes 
and class labels, and overlays enlarged views of detected regions on the original images. Saves annotated images with 
bounding boxes and enlarged detected regions overlaid to OUT_DIR.</p>


<details class="inputs" open>
  <summary>Inputs</summary>
  <p>DIR_TEST (str):              Directory path containing input images.
model (torch.nn.Module):     Trained object detection model.
OUT_DIR (str):               Directory path to save annotated output images.
detection_threshold (float): Minimum confidence score to consider a detection valid.
CLASSES (list):              List of class names corresponding to model output labels.</p>
</details>

<details class="outputs" open>
  <summary>Outputs</summary>
  <p>list: A list containing three elements:
    - bboxes (list):  Detected bounding boxes per image.
    - classes (list): Predicted class labels per image.
    - sscores (list): Detection scores per image.</p>
</details>

            <details class="quote">
              <summary>Source code in <code>library/inferencing.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">inference_images_figs</span><span class="p">(</span><span class="n">DIR_TEST</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">OUT_DIR</span><span class="p">,</span> <span class="n">detection_threshold</span><span class="p">,</span> <span class="n">CLASSES</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs inference on images in a directory using the given model, annotates detected objects with bounding boxes </span>
<span class="sd">    and class labels, and overlays enlarged views of detected regions on the original images. Saves annotated images with </span>
<span class="sd">    bounding boxes and enlarged detected regions overlaid to OUT_DIR.</span>

<span class="sd">    Inputs:</span>
<span class="sd">        DIR_TEST (str):              Directory path containing input images.</span>
<span class="sd">        model (torch.nn.Module):     Trained object detection model.</span>
<span class="sd">        OUT_DIR (str):               Directory path to save annotated output images.</span>
<span class="sd">        detection_threshold (float): Minimum confidence score to consider a detection valid.</span>
<span class="sd">        CLASSES (list):              List of class names corresponding to model output labels.</span>

<span class="sd">    Outputs:</span>
<span class="sd">        list: A list containing three elements:</span>
<span class="sd">            - bboxes (list):  Detected bounding boxes per image.</span>
<span class="sd">            - classes (list): Predicted class labels per image.</span>
<span class="sd">            - sscores (list): Detection scores per image.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">imagePath</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DIR_TEST</span><span class="si">}</span><span class="s2">/*.png&quot;</span><span class="p">)</span>
    <span class="n">image_extensions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;gif&#39;</span><span class="p">,</span> <span class="s1">&#39;bmp&#39;</span><span class="p">,</span> <span class="s1">&#39;tiff&#39;</span><span class="p">,</span> <span class="s1">&#39;webp&#39;</span><span class="p">,</span> <span class="s1">&#39;tif&#39;</span><span class="p">]</span>
    <span class="n">all_extensions</span> <span class="o">=</span> <span class="n">image_extensions</span> <span class="o">+</span> <span class="p">[</span><span class="n">ext</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">image_extensions</span><span class="p">]</span>  <span class="c1"># Add uppercase versions</span>
    <span class="k">for</span> <span class="n">extension</span> <span class="ow">in</span> <span class="n">all_extensions</span><span class="p">:</span>
        <span class="n">imagePath</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">DIR_TEST</span><span class="si">}</span><span class="s2">/*.</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

    <span class="n">all_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">image_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">imagePath</span><span class="p">]</span>
    <span class="n">all_images</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>
    <span class="n">bboxes</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>
    <span class="n">sscores</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">el</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_images</span><span class="p">):</span>
        <span class="n">orig_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">DIR_TEST</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">el</span><span class="p">)</span>
        <span class="c1"># BGR to RGB</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="c1"># Normalize the pixel values (between 0 and 1)</span>
        <span class="n">image</span> <span class="o">/=</span> <span class="mf">255.0</span>
        <span class="c1"># Rearrange color channels</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="c1"># Convert to tensor</span>
        <span class="n">image_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="c1"># Add batch dimension</span>
        <span class="n">image_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image_tensor</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;boxes&#39;</span><span class="p">])</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;boxes&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;scores&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">sscores</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span>
            <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="n">bboxes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">boxes</span>
            <span class="n">draw_boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 

            <span class="n">pred_classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">CLASSES</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pred_classes</span><span class="p">)</span>
            <span class="n">pred_classes</span> <span class="o">=</span> <span class="n">pred_classes</span><span class="p">[</span><span class="n">scores</span> <span class="o">&gt;=</span> <span class="n">detection_threshold</span><span class="p">]</span>
            <span class="n">classes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_classes</span>

            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">box</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">draw_boxes</span><span class="p">):</span>
                <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">box</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">pred_classes</span><span class="p">[</span><span class="n">j</span><span class="p">]),</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">-</span> <span class="mi">5</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

                <span class="c1"># Extract and enlarge the detected region</span>
                <span class="n">detected_img</span> <span class="o">=</span> <span class="n">orig_image</span><span class="p">[</span><span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">]</span>
                <span class="n">factor</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Change factor to desired zoom</span>
                <span class="n">enlarged_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">detected_img</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fx</span><span class="o">=</span><span class="n">factor</span><span class="p">,</span> <span class="n">fy</span><span class="o">=</span><span class="n">factor</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">INTER_LINEAR</span><span class="p">)</span>

                <span class="c1"># Calculate where to place the enlarged image on the original</span>
                <span class="n">eh</span><span class="p">,</span> <span class="n">ew</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">enlarged_img</span><span class="o">.</span><span class="n">shape</span>
                <span class="n">ex</span><span class="p">,</span> <span class="n">ey</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>  <span class="c1"># Starting coordinates for the enlarged image (top left)</span>

                <span class="c1"># Ensure the enlarged image does not go out of the bounds of the original image</span>
                <span class="k">if</span> <span class="n">ey</span> <span class="o">+</span> <span class="n">eh</span> <span class="o">&gt;</span> <span class="n">orig_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="n">ey</span> <span class="o">=</span> <span class="n">orig_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">eh</span>
                <span class="k">if</span> <span class="n">ex</span> <span class="o">+</span> <span class="n">ew</span> <span class="o">&gt;</span> <span class="n">orig_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                    <span class="n">ex</span> <span class="o">=</span> <span class="n">orig_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">ew</span>

                <span class="c1"># Overlay the enlarged image on the original image</span>
                <span class="n">orig_image</span><span class="p">[</span><span class="n">ey</span><span class="p">:</span><span class="n">ey</span><span class="o">+</span><span class="n">eh</span><span class="p">,</span> <span class="n">ex</span><span class="p">:</span><span class="n">ex</span><span class="o">+</span><span class="n">ew</span><span class="p">]</span> <span class="o">=</span> <span class="n">enlarged_img</span>

                <span class="c1"># Draw lines connecting the small and enlarged boxes</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">line</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> <span class="p">(</span><span class="n">ex</span><span class="p">,</span> <span class="n">ey</span><span class="p">),</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">line</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">),</span> <span class="p">(</span><span class="n">ex</span> <span class="o">+</span> <span class="n">ew</span><span class="p">,</span> <span class="n">ey</span> <span class="o">+</span> <span class="n">eh</span><span class="p">),</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

            <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">OUT_DIR</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">el</span><span class="p">,</span> <span class="n">orig_image</span><span class="p">)</span>  <span class="c1"># Save the modified image</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> done...&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TEST PREDICTIONS COMPLETE&#39;</span><span class="p">)</span> 
    <span class="k">return</span> <span class="p">[</span><span class="n">bboxes</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">sscores</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../image_augs/" class="btn btn-neutral float-left" title="ez-frcnn.image_augs"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../plotting/" class="btn btn-neutral float-right" title="ez-frcnn.plotting">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../image_augs/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../plotting/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
